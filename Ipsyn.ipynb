{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Section 1:\n",
        "Run these cells to evaluate transcripts with chat-gpt"
      ],
      "metadata": {
        "id": "JaTb3iRQ3lgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "\n",
        "!pip install PyGithub openai"
      ],
      "metadata": {
        "id": "Ldjmsl0Em4-C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from github import Github\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "TcchPZM7m-5d"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive to save output files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdbJglJnxoTc",
        "outputId": "85cc9086-5be0-4463-8a4a-0e70ac7962cf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up openAI Api key\n",
        "\n",
        "from getpass import getpass\n",
        "api_key = getpass('Enter your OpenAI API key: ')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siSLzJTkqREO",
        "outputId": "89bb71bc-3c11-408a-ea8a-3ed71299a3f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "\n",
        "GITHUB_REPO_URL = 'https://github.com/lfedronic/Ipsyn'\n",
        "GITHUB_FOLDER_PATH = 'Sarah_Transcripts'  # Replace with desired folder of transcripts from the git repo\n",
        "OUTPUT_FOLDER = '/content/drive/My Drive/llm-ipsyn'.\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "MODEL_NAME = 'gpt-4o-mini'\n",
        "TEMP = 0\n",
        "MAX_TOKENS = 7500  # Configured for the current prompt so that the model fully completes ipsyn\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "Y56A_pqlnCTH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to download files from GitHub\n",
        "def download_files_from_github(repo_url, folder_path):\n",
        "    g = Github()\n",
        "    repo_name = '/'.join(repo_url.split('/')[-2:])\n",
        "\n",
        "    repo = g.get_repo(repo_name)\n",
        "    contents = repo.get_contents(folder_path)\n",
        "\n",
        "    for content_file in contents:\n",
        "        if content_file.type == 'file' and content_file.name.endswith('.txt'):\n",
        "            file_content = requests.get(content_file.download_url).text\n",
        "            with open(content_file.name, 'w') as f:\n",
        "                f.write(file_content)\n",
        "            print(f'Downloaded {content_file.name}')"
      ],
      "metadata": {
        "id": "P9Dw_-zlnIPa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_files_from_github(GITHUB_REPO_URL, GITHUB_FOLDER_PATH)"
      ],
      "metadata": {
        "id": "qCqMHuVynI1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process transcript and call OpenAI API\n",
        "def process_transcript(file_name):\n",
        "    client = OpenAI()\n",
        "    with open(file_name, 'r') as file:\n",
        "        transcript = file.read()\n",
        "    # You can edit this prompt\n",
        "    prompt = f\"\"\"Objective:\n",
        "You are to evaluate the following transcript according to the Index of Productive Syntax. Specifically, you should go through the transcript one line at a time, checking for the presence of each grammatical item in the scoring table. You should keep track of how many times each scoring table item is satisfied by the line from the transcript. Each instance adds one to the item’s score. Once an item reaches a score of 2, stop looking for further instances–2 is the maximum score any one item can receive. Do not award points based on implied or inferred words; just use what is explicitly stated in the transcript.\n",
        "\n",
        "Scoring Table:\n",
        "N1: Noun\n",
        "N2: Pronoun\n",
        "N3: Modifier\n",
        "N4:Two-word Noun Phrase\n",
        "N5: Determiner + Noun\n",
        "N6: Verb + Two-word Noun Phrase\n",
        "N7: Noun Plural\n",
        "N8: Two-word Noun Phrase + Verb\n",
        "N9: Three-word Noun Phrase\n",
        "N10: Noun Phrase + Adverb\n",
        "N11: Bound Morpheme\n",
        "V1: Verb\n",
        "V2: Verb Particle or Preposition\n",
        "V3: Prepositional Phrase\n",
        "V4: Noun + Copula + Noun\n",
        "V5: Catenative\n",
        "V6: Auxiliary Be, Do, Have\n",
        "V7: Progressive -ing\n",
        "V8: Adverb\n",
        "V9: Modal + Verb\n",
        "V10: Third-person Singular Present\n",
        "V11: Past Tense Modal\n",
        "V12: Regular Past Tense\n",
        "V13: Past Tense Auxiliary\n",
        "V14: Medial Adverb\n",
        "V15: Ellipsis\n",
        "V16: Past Copula\n",
        "V17: Bound Morpheme\n",
        "Q1: contains a question mark\n",
        "Q2: wh-word alone; routine question with or without a verb\n",
        "Q3: Simple Negation\n",
        "Q4: Wh-Question + Verb\n",
        "Q5: Subject + negation + Verb\n",
        "Q6: Wh-Question with Subject-Auxiliary inversion\n",
        "Q7: Negation copula, modal or auxiliary\n",
        "Q8: Yes/No Question with Subject–Auxiliary Inversion\n",
        "Q9: Wh-Question\n",
        "Q10: Tag Question\n",
        "Q11: Negation Question with Subject–Auxiliary Inversion\n",
        "S1: Two words\n",
        "S2: Subject + Verb\n",
        "S3: Verb + Object\n",
        "S4: Subject + Verb + Object\n",
        "S5: Any Conjunction\n",
        "S6: Any Two Verbs\n",
        "S7: Conjoined Phrases\n",
        "S8: Infinitive\n",
        "S9: Let/Make/Help/Watch\n",
        "S10: Subordinating Conjunction\n",
        "S11: Mental State Verb\n",
        "S12: Conjoined Clauses\n",
        "S13: If or Wh-Clause\n",
        "S14: Bitransitive Predicate\n",
        "S15: Three or More Verbs\n",
        "S16: Relative Clause\n",
        "S17: Infinitival Clause\n",
        "S18: Gerund\n",
        "S19: Left or Center-Embedded Clause\n",
        "S20: Passive\n",
        "\n",
        "{transcript}\n",
        "\n",
        "Steps:\n",
        "1) Go through the transcript line by line, checking for the presence of each grammatical item.\n",
        "2) For each item you encounter, only list the applicable item(s) and scores.\n",
        "3) Once you have finished parsing the entire transcript, compile each item's score\n",
        "3) Finally, present the final score by capping each item at a maximum of 2 and responding in this format:\n",
        "Final score:\n",
        "N1, #\n",
        "N2, #\n",
        "...\n",
        "S20, #\n",
        "\"\"\"\n",
        "    completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        model=MODEL_NAME,\n",
        "        max_tokens=MAX_TOKENS,\n",
        "        temperature=TEMP\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "_lCP9uXAnVoL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each downloaded transcript and save the result in the google drive folder you set in configuration\n",
        "for file_name in os.listdir():\n",
        "    if file_name.endswith('.txt'):\n",
        "        result = process_transcript(file_name)\n",
        "        output_file_name = os.path.join(OUTPUT_FOLDER, f'evaluation_{file_name}')\n",
        "        with open(output_file_name, 'w') as output_file:\n",
        "            output_file.write(result)\n",
        "        print(f'Saved evaluation for {file_name} to {output_file_name}')"
      ],
      "metadata": {
        "id": "1JbIsdfdnpSs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}